{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "508cbd30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from algo import GreedyArrangeAlgo\n",
    "from bayesian import BayesianService\n",
    "from estimator import Estimator\n",
    "\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import cosine\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac873e90",
   "metadata": {},
   "source": [
    "# settings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8cb39b0",
   "metadata": {},
   "source": [
    "## id読み取り"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b21643b",
   "metadata": {},
   "outputs": [],
   "source": [
    "artist_dict = defaultdict()\n",
    "\n",
    "with open('../modify_dataset/spotify_playlists_dataset/artist_id.tsv', mode = 'r') as f:\n",
    "    \n",
    "    for line in f.readlines():\n",
    "        artistname, id = line.split('\\t')\n",
    "        artist_dict[artistname] = int(id)\n",
    "        \n",
    "track_dict = defaultdict()\n",
    "track_artist_id = defaultdict()\n",
    "\n",
    "with open('../modify_dataset/spotify_playlists_dataset/track_id.tsv', mode = 'r') as f:\n",
    "    \n",
    "    for line in f.readlines():\n",
    "        artistname, trackname, id = line.split('\\t')\n",
    "        track_dict[ (artistname, trackname) ] = int(id)\n",
    "        track_artist_id[ int(id) ] = artist_dict[artistname]\n",
    "        \n",
    "playlist_list = []\n",
    "with open('../modify_dataset/spotify_playlists_dataset/playlist_id.tsv', mode = 'r') as f:\n",
    "    \n",
    "    for line in f.readlines():\n",
    "        data = line.split('\\t')\n",
    "        playlist = tuple(data[1:])\n",
    "        playlist_list.append(playlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "114e93c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/192080 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 192080/192080 [00:06<00:00, 31282.93it/s]\n"
     ]
    }
   ],
   "source": [
    "playlist_artist_counts = {}\n",
    "artist_in_playlist_count = defaultdict(int)\n",
    "\n",
    "for p_id, playlist in tqdm( enumerate(playlist_list), total = len(playlist_list) ):\n",
    "\n",
    "    artist_count = defaultdict(int)\n",
    "\n",
    "    if len(playlist) < 2:\n",
    "        continue\n",
    "    \n",
    "    for track in playlist:\n",
    "        artist = track_artist_id[int(track)]\n",
    "        artist_count[ artist ] += 1\n",
    "        artist_in_playlist_count[ artist ] += 1\n",
    "        \n",
    "    playlist_artist_counts[p_id] = artist_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d60ebc2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import lil_matrix, coo_matrix\n",
    "\n",
    "def normalize_data(data):\n",
    "    \n",
    "    # 各プレイリストのアーティスト回数について\n",
    "    for pid, playlist_artist_ids in data.items():\n",
    "        max_term = max(playlist_artist_ids.values())\n",
    "        \n",
    "        # プレイリストの各アーティストについて\n",
    "        for artist_id, count in playlist_artist_ids.items():\n",
    "            \n",
    "            # tf-idf計算\n",
    "            tf = count / max_term\n",
    "            idf = np.log(len(data) / artist_in_playlist_count[artist_id])\n",
    "            \n",
    "            # 受け取ったプレイリスト-アーティスト回数をtf-idfに\n",
    "            playlist_artist_ids[artist_id] = tf * idf\n",
    "            \n",
    "    return data\n",
    "\n",
    "def init_matrix(data):\n",
    "    n = len(artist_dict)\n",
    "    m = len(data)\n",
    "    matrix = lil_matrix((m, n), dtype=np.float32)\n",
    "    for i, playlist_artist_ids in enumerate(data.values()):\n",
    "        for artist_id, count in playlist_artist_ids.items():\n",
    "            matrix[i, artist_id] = count\n",
    "    return coo_matrix(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "beaff702",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = normalize_data(playlist_artist_counts)\n",
    "playlist_artist_matrix = init_matrix(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f6fc31fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 192080/192080 [00:04<00:00, 46420.85it/s]\n",
      "100%|██████████| 192080/192080 [00:04<00:00, 46129.63it/s]\n"
     ]
    }
   ],
   "source": [
    "track_count = defaultdict(int)\n",
    "\n",
    "for p_id, playlist in tqdm( enumerate(playlist_list), total = len(playlist_list) ):\n",
    "    \n",
    "    for track in playlist:\n",
    "        track_count[ track ] += 1\n",
    "\n",
    "pl_pops = {}\n",
    "for p_id, playlist in tqdm( enumerate(playlist_list), total = len(playlist_list) ):\n",
    "    \n",
    "    sum_popularity = 0\n",
    "    for track in playlist:\n",
    "        sum_popularity += math.log(track_count[track])\n",
    "\n",
    "    pl_pops[p_id] = sum_popularity/len(playlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "68e21d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./variances.tsv', mode = 'r') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "var_data = defaultdict(lambda : dict())\n",
    "for i, line in enumerate(lines):\n",
    "    line = line.split('\\t')\n",
    "    if len(line) != 6:\n",
    "        print(i)\n",
    "    p_id, pid, pl_var, p_c, sq_var, s_c = line\n",
    "    if p_id != pid:\n",
    "        print(p_id)\n",
    "    \n",
    "    \n",
    "    if float(pl_var) > 10e-6:\n",
    "        var_data[int(p_id)]['coherence'] = 1.0 - float(sq_var) /float(pl_var)\n",
    "        var_data[int(p_id)]['pl_var'] = float(pl_var)\n",
    "        var_data[int(p_id)]['sq_var'] = float(sq_var) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "305add42",
   "metadata": {},
   "outputs": [
    {
     "ename": "PicklingError",
     "evalue": "Can't pickle <function <lambda> at 0x7fad6180ed40>: attribute lookup <lambda> on __main__ failed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPicklingError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpickle\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./pkl/var_data.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m----> 4\u001b[0m     \u001b[43mpickle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvar_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mPicklingError\u001b[0m: Can't pickle <function <lambda> at 0x7fad6180ed40>: attribute lookup <lambda> on __main__ failed"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "with open('./pkl/var_data.pkl', 'wb') as f:\n",
    "    pickle.dump(var_data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5b3dbfba",
   "metadata": {},
   "outputs": [],
   "source": [
    "coherence_table = defaultdict(list)\n",
    "for p_id, value in var_data.items():\n",
    "    playlist = playlist_list[p_id]\n",
    "    coherence_table['id'].append(p_id)\n",
    "    l = len(playlist)\n",
    "    coherence_table['length'].append(l)\n",
    "    coherence_table['log_length'].append(math.log(l))\n",
    "    coherence_table['popularity'].append(pl_pops[p_id])\n",
    "    coherence_table['coherence'].append(value['coherence'])\n",
    "\n",
    "coherence_table = pd.DataFrame.from_dict(coherence_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae33be21",
   "metadata": {},
   "source": [
    "# 並び替え"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22539b6f",
   "metadata": {},
   "source": [
    "## setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4b17d81c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 111841/111841 [42:20<00:00, 44.03it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training transition\n",
      "finished training transition\n",
      "training coherence\n",
      "finished training coherence\n"
     ]
    }
   ],
   "source": [
    "estimator = Estimator()\n",
    "estimator.load_from_data(playlist_list, playlist_artist_matrix, track_artist_id, coherence_table)\n",
    "bayesian = BayesianService(threshold=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "22e390c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('./pkl/estimator.pkl', 'wb') as f:\n",
    "    pickle.dump(estimator, f)\n",
    "\n",
    "with open('./pkl/coherence_table.pkl', 'wb') as f:\n",
    "    pickle.dump(coherence_table, f)\n",
    "    \n",
    "with open('./pkl/track_artist_id.pkl', 'wb') as f:\n",
    "    pickle.dump(track_artist_id, f)\n",
    "    \n",
    "with open('./pkl/playlist_artist_matrix.pkl', 'wb') as f:\n",
    "    pickle.dump(playlist_artist_matrix, f)\n",
    "    \n",
    "with open('./pkl/playlist_list.pkl', 'wb') as f:\n",
    "    pickle.dump(playlist_list, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3714d749",
   "metadata": {},
   "source": [
    "## 読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf6cd6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./variances.tsv', mode = 'r') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "var_data = defaultdict(lambda : dict())\n",
    "for i, line in enumerate(lines):\n",
    "    line = line.split('\\t')\n",
    "    if len(line) != 6:\n",
    "        print(i)\n",
    "    p_id, pid, pl_var, p_c, sq_var, s_c = line\n",
    "    if p_id != pid:\n",
    "        print(p_id)\n",
    "    \n",
    "    \n",
    "    if float(pl_var) > 0:\n",
    "        var_data[int(p_id)]['coherence'] = 1.0 - float(sq_var) /float(pl_var)\n",
    "        var_data[int(p_id)]['pl_var'] = float(pl_var)\n",
    "        var_data[int(p_id)]['sq_var'] = float(sq_var) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1fa81ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('./pkl/estimator.pkl', 'rb') as f:\n",
    "    estimator = pickle.load(f)\n",
    "\n",
    "with open('./pkl/coherence_table.pkl', 'rb') as f:\n",
    "    coherence_table = pickle.load(f)\n",
    "    \n",
    "with open('./pkl/track_artist_id.pkl', 'rb') as f:\n",
    "    track_artist_id = pickle.load(f)\n",
    "    \n",
    "with open('./pkl/playlist_artist_matrix.pkl', 'rb') as f:\n",
    "    playlist_artist_matrix = pickle.load(f)\n",
    "    \n",
    "with open('./pkl/playlist_list.pkl', 'rb') as f:\n",
    "    playlist_list = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13581bf",
   "metadata": {},
   "source": [
    "## 実行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14e856c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0: dist=  0, coh_error=0.0007\n",
      "  1: dist=  1, coh_error=0.0000, trans_error=-0.0000\n",
      "  2: dist=  1, coh_error=0.0000, trans_error=-0.0000\n",
      "  3: dist=  1, coh_error=0.0000, trans_error=-0.0000\n",
      "  4: dist=  1, coh_error=0.0000, trans_error=-0.0000\n",
      "  5: dist=  1, coh_error=0.0000, trans_error=-0.0000\n",
      "  6: dist=  1, coh_error=0.0000, trans_error= 0.0000\n",
      "  7: dist=  1, coh_error=0.0000, trans_error= 0.0000\n",
      "  8: dist=  1, coh_error=0.0000, trans_error= 0.0000\n",
      "  9: dist=  1, coh_error=0.0000, trans_error= 0.0000\n",
      " 10: dist=  1, coh_error=0.0000, trans_error= 0.0000\n",
      " 11: dist=  1, coh_error=0.0000, trans_error= 0.0000\n",
      " 12: dist=  2, coh_error=0.0000, trans_error= 0.0000\n",
      " 13: dist= 19, coh_error=0.0000, trans_error= 0.0000\n",
      " 14: dist=  1, coh_error=0.0000, trans_error= 0.0000\n",
      " 15: dist=  2, coh_error=0.0000, trans_error= 0.0000\n",
      " 16: dist=  5, coh_error=0.0000, trans_error= 0.0000\n",
      " 17: dist=  2, coh_error=0.0000, trans_error= 0.0000\n",
      " 18: dist= 11, coh_error=0.0000, trans_error= 0.0000\n",
      " 19: dist= 26, coh_error=0.0000, trans_error= 0.0000\n",
      " 20: dist=  2, coh_error=0.0000, trans_error= 0.0000\n",
      " 21: dist= 14, coh_error=0.0000, trans_error= 0.0000\n",
      " 22: dist= 19, coh_error=0.0000, trans_error= 0.0000\n",
      "Total trans error: -3.988644590648758e-07\n",
      "283.88130044937134\n",
      "('0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '61', '62', '63', '64', '65', '66\\n')\n",
      "[<node.Node object at 0x7f6b8f21fe10>, <node.Node object at 0x7f6b7b408890>, <node.Node object at 0x7f6bcd08e190>, <node.Node object at 0x7f6c3273c5d0>, <node.Node object at 0x7f6b8f22abd0>, <node.Node object at 0x7f6b8f22add0>, <node.Node object at 0x7f6bcd08e1d0>, <node.Node object at 0x7f6b8f219350>, <node.Node object at 0x7f6bcd08f0d0>, <node.Node object at 0x7f6bcd08e3d0>, <node.Node object at 0x7f6bcd08e010>, <node.Node object at 0x7f6bcd08e5d0>, <node.Node object at 0x7f6b7b4001d0>, <node.Node object at 0x7f6bcd08e510>, <node.Node object at 0x7f6bcd08c0d0>, <node.Node object at 0x7f6b7b401d50>, <node.Node object at 0x7f6b7b401c10>, <node.Node object at 0x7f6b8e5be390>, <node.Node object at 0x7f6b7b40dad0>, <node.Node object at 0x7f6b7b40dc50>, <node.Node object at 0x7f6b7b40c2d0>, <node.Node object at 0x7f6b7b40e250>, <node.Node object at 0x7f6b7b40ed10>, <node.Node object at 0x7f6b8e8003d0>, <node.Node object at 0x7f6b8f221250>, <node.Node object at 0x7f6b8f2230d0>, <node.Node object at 0x7f6b8f221550>, <node.Node object at 0x7f6b8f220b10>, <node.Node object at 0x7f6b8e5bf550>, <node.Node object at 0x7f6bcd7d9310>, <node.Node object at 0x7f6bcbd34bd0>, <node.Node object at 0x7f6b8e54f4d0>, <node.Node object at 0x7f6b8e5bf690>, <node.Node object at 0x7f6b8e5bf190>, <node.Node object at 0x7f6b8e5be090>, <node.Node object at 0x7f6b8e5bd410>, <node.Node object at 0x7f6bcd08bd10>, <node.Node object at 0x7f6b8e5beb90>, <node.Node object at 0x7f6b8e5bfb50>, <node.Node object at 0x7f6b8f221ad0>, <node.Node object at 0x7f6b8e5bda50>, <node.Node object at 0x7f6b8e5bf910>, <node.Node object at 0x7f6b8e54efd0>, <node.Node object at 0x7f6b8e54c9d0>, <node.Node object at 0x7f6b8e5bf110>, <node.Node object at 0x7f6b8e5bcbd0>, <node.Node object at 0x7f6b8e5bf5d0>, <node.Node object at 0x7f6b8e54d810>, <node.Node object at 0x7f6b8e54cd10>, <node.Node object at 0x7f6b8e54e4d0>, <node.Node object at 0x7f6b8e54ec90>, <node.Node object at 0x7f6b8e54dbd0>, <node.Node object at 0x7f6b8e54c110>, <node.Node object at 0x7f6b8e54e650>, <node.Node object at 0x7f6b8e54f0d0>, <node.Node object at 0x7f6b8e54c890>, <node.Node object at 0x7f6b8e5bdb50>, <node.Node object at 0x7f6b8e5bef90>, <node.Node object at 0x7f6b8e54da50>, <node.Node object at 0x7f6b8e54f490>, <node.Node object at 0x7f6b8e54fd90>, <node.Node object at 0x7f6b8e54e810>, <node.Node object at 0x7f6b8e5bfbd0>, <node.Node object at 0x7f6b8e54f9d0>, <node.Node object at 0x7f6b8e54f610>, <node.Node object at 0x7f6b8e54eb10>, <node.Node object at 0x7f6b8e54d8d0>]\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "bayesian = BayesianService(threshold=0.7)\n",
    "\n",
    "p_id = 0\n",
    "playlist = playlist_list[p_id]\n",
    "algo = GreedyArrangeAlgo(p_id, playlist)\n",
    "algo.load_from_data(playlist, estimator, coherence_table,bayesian, playlist_artist_matrix, track_artist_id)\n",
    "\n",
    "start = time.time()\n",
    "rearranged_p = algo.train(True)\n",
    "print(time.time()-start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d83cc97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '61', '62', '63', '64', '65', '66\\n')\n",
      "[[0], [1], [7], [3], [4], [5], [6], [2], [8], [10], [9], [11], [14], [12], [13], [15], [16], [36], [19], [21], [20], [18], [22], [23], [24], [25], [26], [27], [39], [29], [30], [57], [33], [32], [34], [35], [17], [37], [38], [28], [40], [41], [58], [63], [44], [45], [46], [47], [49], [48], [50], [51], [52], [53], [54], [55], [42], [31], [56], [59], [61], [60], [43], [62], [64], [65], [66]]\n"
     ]
    }
   ],
   "source": [
    "print(playlist)\n",
    "print([track.tracks for track in rearranged_p])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "95938e98",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/111841 [00:09<281:36:24,  9.06s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m algo \u001b[38;5;241m=\u001b[39m GreedyArrangeAlgo(p_id, playlist)\n\u001b[1;32m      9\u001b[0m algo\u001b[38;5;241m.\u001b[39mload_from_data(playlist, estimator, coherence_table,bayesian, playlist_artist_matrix, track_artist_id)\n\u001b[0;32m---> 11\u001b[0m rearranged\u001b[38;5;241m.\u001b[39mappend(\u001b[43malgo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/master_exp/coherence/algo.py:130\u001b[0m, in \u001b[0;36mGreedyArrangeAlgo.train\u001b[0;34m(self, output)\u001b[0m\n\u001b[1;32m    128\u001b[0m playlist_prime \u001b[38;5;241m=\u001b[39m playlist\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m    129\u001b[0m playlist_prime[i], playlist_prime[i\u001b[38;5;241m+\u001b[39mdist] \u001b[38;5;241m=\u001b[39m playlist_prime[i\u001b[38;5;241m+\u001b[39mdist], playlist_prime[i]\n\u001b[0;32m--> 130\u001b[0m playlist_prime_coh_error \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcoherence_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mplaylist_prime\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m playlist_prime_coh_error \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m playlist_coh_error:\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "File \u001b[0;32m~/master_exp/coherence/algo.py:68\u001b[0m, in \u001b[0;36mGreedyArrangeAlgo.coherence_error\u001b[0;34m(self, nodes)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcoherence_error\u001b[39m(\u001b[38;5;28mself\u001b[39m, nodes: \u001b[38;5;28mlist\u001b[39m[Node]):\n\u001b[0;32m---> 68\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39msum(np\u001b[38;5;241m.\u001b[39msquare(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_coherence \u001b[38;5;241m-\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_coherence\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnodes\u001b[49m\u001b[43m)\u001b[49m))\n",
      "File \u001b[0;32m~/master_exp/coherence/algo.py:78\u001b[0m, in \u001b[0;36mGreedyArrangeAlgo.get_coherence\u001b[0;34m(self, nodes)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_coherence\u001b[39m(\u001b[38;5;28mself\u001b[39m, nodes: \u001b[38;5;28mlist\u001b[39m[Node]):\n\u001b[0;32m---> 78\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m-\u001b[39m \u001b[43mget_sq_variance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnodes\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpl_variance\n",
      "File \u001b[0;32m~/master_exp/coherence/algo.py:48\u001b[0m, in \u001b[0;36mget_sq_variance\u001b[0;34m(nodes)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m node \u001b[38;5;129;01min\u001b[39;00m nodes:\n\u001b[1;32m     47\u001b[0m     artists \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m [f \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m node\u001b[38;5;241m.\u001b[39martists]\n\u001b[0;32m---> 48\u001b[0m sq_variance \u001b[38;5;241m=\u001b[39m \u001b[43msequential_variance\u001b[49m\u001b[43m(\u001b[49m\u001b[43martists\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m sq_variance\n",
      "File \u001b[0;32m~/master_exp/coherence/algo.py:31\u001b[0m, in \u001b[0;36msequential_variance\u001b[0;34m(embeddings)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, a_artists \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(embeddings[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]):\n\u001b[1;32m     30\u001b[0m     b_artists \u001b[38;5;241m=\u001b[39m embeddings[i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m---> 31\u001b[0m     sum_ \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43membedding_similarity\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma_artists\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb_artists\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# 分散を返す\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m sum_ \u001b[38;5;241m/\u001b[39m (n \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m\n",
      "File \u001b[0;32m~/master_exp/coherence/algo.py:10\u001b[0m, in \u001b[0;36membedding_similarity\u001b[0;34m(a_embeddings, b_embeddings)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21membedding_similarity\u001b[39m(a_embeddings, b_embeddings):\n\u001b[0;32m---> 10\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mmean(\u001b[43mcosine_distances\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma_embeddings\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb_embeddings\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/anaconda3/envs/coherence/lib/python3.11/site-packages/sklearn/utils/_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    211\u001b[0m         )\n\u001b[1;32m    212\u001b[0m     ):\n\u001b[0;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    223\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/coherence/lib/python3.11/site-packages/sklearn/metrics/pairwise.py:1130\u001b[0m, in \u001b[0;36mcosine_distances\u001b[0;34m(X, Y)\u001b[0m\n\u001b[1;32m   1095\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Compute cosine distance between samples in X and Y.\u001b[39;00m\n\u001b[1;32m   1096\u001b[0m \n\u001b[1;32m   1097\u001b[0m \u001b[38;5;124;03mCosine distance is defined as 1.0 minus the cosine similarity.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;124;03m       [0.42..., 0.18...]])\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1129\u001b[0m \u001b[38;5;66;03m# 1.0 - cosine_similarity(X, Y) without copy\u001b[39;00m\n\u001b[0;32m-> 1130\u001b[0m S \u001b[38;5;241m=\u001b[39m \u001b[43mcosine_similarity\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m S \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1132\u001b[0m S \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/coherence/lib/python3.11/site-packages/sklearn/utils/_param_validation.py:186\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    184\u001b[0m global_skip_validation \u001b[38;5;241m=\u001b[39m get_config()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskip_parameter_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m global_skip_validation:\n\u001b[0;32m--> 186\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    188\u001b[0m func_sig \u001b[38;5;241m=\u001b[39m signature(func)\n\u001b[1;32m    190\u001b[0m \u001b[38;5;66;03m# Map *args/**kwargs to the function signature\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/coherence/lib/python3.11/site-packages/sklearn/metrics/pairwise.py:1685\u001b[0m, in \u001b[0;36mcosine_similarity\u001b[0;34m(X, Y, dense_output)\u001b[0m\n\u001b[1;32m   1683\u001b[0m     Y_normalized \u001b[38;5;241m=\u001b[39m X_normalized\n\u001b[1;32m   1684\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1685\u001b[0m     Y_normalized \u001b[38;5;241m=\u001b[39m \u001b[43mnormalize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   1687\u001b[0m K \u001b[38;5;241m=\u001b[39m safe_sparse_dot(X_normalized, Y_normalized\u001b[38;5;241m.\u001b[39mT, dense_output\u001b[38;5;241m=\u001b[39mdense_output)\n\u001b[1;32m   1689\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m K\n",
      "File \u001b[0;32m~/anaconda3/envs/coherence/lib/python3.11/site-packages/sklearn/utils/_param_validation.py:186\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    184\u001b[0m global_skip_validation \u001b[38;5;241m=\u001b[39m get_config()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskip_parameter_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m global_skip_validation:\n\u001b[0;32m--> 186\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    188\u001b[0m func_sig \u001b[38;5;241m=\u001b[39m signature(func)\n\u001b[1;32m    190\u001b[0m \u001b[38;5;66;03m# Map *args/**kwargs to the function signature\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/coherence/lib/python3.11/site-packages/sklearn/preprocessing/_data.py:1933\u001b[0m, in \u001b[0;36mnormalize\u001b[0;34m(X, norm, axis, copy, return_norm)\u001b[0m\n\u001b[1;32m   1929\u001b[0m     sparse_format \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1931\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(X)\n\u001b[0;32m-> 1933\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1934\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1935\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msparse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1936\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1937\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mthe normalize function\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1938\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_array_api\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msupported_float_dtypes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxp\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1939\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_writeable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1940\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1941\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1942\u001b[0m     X \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mT\n",
      "File \u001b[0;32m~/anaconda3/envs/coherence/lib/python3.11/site-packages/sklearn/utils/validation.py:971\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    969\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sp\u001b[38;5;241m.\u001b[39missparse(array):\n\u001b[1;32m    970\u001b[0m     _ensure_no_complex_data(array)\n\u001b[0;32m--> 971\u001b[0m     array \u001b[38;5;241m=\u001b[39m \u001b[43m_ensure_sparse_format\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    972\u001b[0m \u001b[43m        \u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    973\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    974\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    975\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    976\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    977\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_large_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    978\u001b[0m \u001b[43m        \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    979\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    980\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    981\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ensure_2d \u001b[38;5;129;01mand\u001b[39;00m array\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m    982\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    983\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected 2D input, got input with shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00marray\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    984\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReshape your data either using array.reshape(-1, 1) if \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    985\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myour data has a single feature or array.reshape(1, -1) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    986\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mif it contains a single sample.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    987\u001b[0m         )\n",
      "File \u001b[0;32m~/anaconda3/envs/coherence/lib/python3.11/site-packages/sklearn/utils/validation.py:622\u001b[0m, in \u001b[0;36m_ensure_sparse_format\u001b[0;34m(sparse_container, accept_sparse, dtype, copy, force_all_finite, accept_large_sparse, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    619\u001b[0m     sparse_container \u001b[38;5;241m=\u001b[39m sparse_container\u001b[38;5;241m.\u001b[39mastype(dtype)\n\u001b[1;32m    620\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m copy \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m changed_format:\n\u001b[1;32m    621\u001b[0m     \u001b[38;5;66;03m# force copy\u001b[39;00m\n\u001b[0;32m--> 622\u001b[0m     sparse_container \u001b[38;5;241m=\u001b[39m \u001b[43msparse_container\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    624\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m force_all_finite:\n\u001b[1;32m    625\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(sparse_container, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m~/anaconda3/envs/coherence/lib/python3.11/site-packages/scipy/sparse/_data.py:96\u001b[0m, in \u001b[0;36m_data_matrix.copy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcopy\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m---> 96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_with_data\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/coherence/lib/python3.11/site-packages/scipy/sparse/_compressed.py:1358\u001b[0m, in \u001b[0;36m_cs_matrix._with_data\u001b[0;34m(self, data, copy)\u001b[0m\n\u001b[1;32m   1353\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Returns a matrix with the same sparsity structure as self,\u001b[39;00m\n\u001b[1;32m   1354\u001b[0m \u001b[38;5;124;03mbut with different data.  By default the structure arrays\u001b[39;00m\n\u001b[1;32m   1355\u001b[0m \u001b[38;5;124;03m(i.e. .indptr and .indices) are copied.\u001b[39;00m\n\u001b[1;32m   1356\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1357\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copy:\n\u001b[0;32m-> 1358\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__class__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1359\u001b[0m \u001b[43m                           \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindptr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1360\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mshape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1361\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1362\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1363\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m((data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindptr),\n\u001b[1;32m   1364\u001b[0m                           shape\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape, dtype\u001b[38;5;241m=\u001b[39mdata\u001b[38;5;241m.\u001b[39mdtype)\n",
      "File \u001b[0;32m~/anaconda3/envs/coherence/lib/python3.11/site-packages/scipy/sparse/_compressed.py:98\u001b[0m, in \u001b[0;36m_cs_matrix.__init__\u001b[0;34m(self, arg1, shape, dtype, copy)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;66;03m# Read matrix dimensions given, if any\u001b[39;00m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m shape \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 98\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shape \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_shape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_1d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_array\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;66;03m# shape not already set, try to infer dimensions\u001b[39;00m\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/coherence/lib/python3.11/site-packages/scipy/sparse/_sputils.py:336\u001b[0m, in \u001b[0;36mcheck_shape\u001b[0;34m(args, current_shape, allow_1d)\u001b[0m\n\u001b[1;32m    334\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(new_shape) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m    335\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mshape must be a 2-tuple of positive integers\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 336\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(d \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m new_shape):\n\u001b[1;32m    337\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mshape\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m elements cannot be negative\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    338\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    339\u001b[0m     \u001b[38;5;66;03m# Check the current size only if needed\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/coherence/lib/python3.11/site-packages/scipy/sparse/_sputils.py:336\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    334\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(new_shape) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m    335\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mshape must be a 2-tuple of positive integers\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 336\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(d \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m new_shape):\n\u001b[1;32m    337\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mshape\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m elements cannot be negative\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    338\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    339\u001b[0m     \u001b[38;5;66;03m# Check the current size only if needed\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "rearranged = []\n",
    "bayesian = BayesianService(threshold=0.7)\n",
    "\n",
    "for p_id in tqdm(data.keys(), total=len(data)):\n",
    "    playlist = playlist_list[p_id]\n",
    "    if len(playlist) > 40:\n",
    "        continue\n",
    "    algo = GreedyArrangeAlgo(p_id, playlist)\n",
    "    algo.load_from_data(playlist, estimator, coherence_table,bayesian, playlist_artist_matrix, track_artist_id)\n",
    "\n",
    "    rearranged.append(algo.train())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6ccd19e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 111841/111841 [00:00<00:00, 2836622.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  2.   4.   6.  13.  25.  55. 101. 136. 205.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "p_len = []\n",
    "for p_id in tqdm(data.keys(), total=len(data)):\n",
    "    p_len.append(len(playlist_list[p_id]))\n",
    "\n",
    "print(np.percentile(p_len,[0,5,10,25,50,75,90,95,100]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee832f52",
   "metadata": {},
   "source": [
    "## 少し修正して実行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ca207021",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 4001/111841 [08:36<3:52:09,  7.74it/s] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 17\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# try:\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m algo\u001b[38;5;241m.\u001b[39mpl_variance \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m10e-6\u001b[39m:\n\u001b[0;32m---> 17\u001b[0m     rearranged\u001b[38;5;241m.\u001b[39mappend( (p_id, \u001b[43malgo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m) )\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     19\u001b[0m     outlier\u001b[38;5;241m.\u001b[39mappend(p_id)\n",
      "File \u001b[0;32m~/master_exp/coherence/algo.py:133\u001b[0m, in \u001b[0;36mGreedyArrangeAlgo.train\u001b[0;34m(self, output)\u001b[0m\n\u001b[1;32m    131\u001b[0m playlist_prime \u001b[38;5;241m=\u001b[39m playlist\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m    132\u001b[0m playlist_prime[i], playlist_prime[i\u001b[38;5;241m+\u001b[39mdist] \u001b[38;5;241m=\u001b[39m playlist_prime[i\u001b[38;5;241m+\u001b[39mdist], playlist_prime[i]\n\u001b[0;32m--> 133\u001b[0m playlist_prime_coh_error \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcoherence_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mplaylist_prime\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m playlist_prime_coh_error \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m playlist_coh_error:\n\u001b[1;32m    135\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "File \u001b[0;32m~/master_exp/coherence/algo.py:69\u001b[0m, in \u001b[0;36mGreedyArrangeAlgo.coherence_error\u001b[0;34m(self, nodes)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcoherence_error\u001b[39m(\u001b[38;5;28mself\u001b[39m, nodes: \u001b[38;5;28mlist\u001b[39m[Node]):\n\u001b[0;32m---> 69\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39msum(\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msquare\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_coherence\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_coherence\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnodes\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "rearranged = []\n",
    "outlier = []\n",
    "\n",
    "bayesian = BayesianService(threshold=0.7)\n",
    "\n",
    "for p_id, data in tqdm(var_data.items(), total=len(var_data)):\n",
    "\n",
    "    playlist = playlist_list[p_id]\n",
    "    pl_variance = data['pl_var']\n",
    "    if len(playlist) > 50 or len(playlist) < 3:\n",
    "        continue\n",
    "    algo = GreedyArrangeAlgo(p_id, playlist)\n",
    "    algo.load_from_data(playlist, estimator, coherence_table,bayesian, playlist_artist_matrix, track_artist_id)\n",
    "\n",
    "    # try:\n",
    "    if algo.pl_variance > 10e-6:\n",
    "        rearranged.append( (p_id, algo.train()) )\n",
    "    else:\n",
    "        outlier.append(p_id)\n",
    "    # except Exception as e:\n",
    "    #     print(e)\n",
    "    #     print(algo.pl_variance)\n",
    "    #     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c028de3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 111841/111841 [00:00<00:00, 2427111.67it/s]\n",
      "100%|██████████| 78575/78575 [41:09<00:00, 31.82it/s]  \n"
     ]
    }
   ],
   "source": [
    "from concurrent.futures import ProcessPoolExecutor\n",
    "\n",
    "bayesian = BayesianService(threshold=0.7)\n",
    "\n",
    "def parallel_fuc(p_id, playlist):\n",
    "    if len(playlist) > 50 or len(playlist) < 3:\n",
    "        return (p_id, [])\n",
    "    \n",
    "    algo = GreedyArrangeAlgo(p_id, playlist)\n",
    "    algo.load_from_data(playlist, estimator, coherence_table,bayesian, playlist_artist_matrix, track_artist_id)\n",
    "    \n",
    "    if algo.pl_variance > 10e-6:\n",
    "        return (p_id, algo.train())\n",
    "    else:\n",
    "        return (p_id, [])\n",
    "\n",
    "rearranged = []\n",
    "outlier = []\n",
    "\n",
    "ids = []\n",
    "playlists = []\n",
    "\n",
    "for p_id, data in tqdm(var_data.items(), total=len(var_data)):\n",
    "    playlist = playlist_list[p_id]\n",
    "    if len(playlist) > 50 or len(playlist) < 3:\n",
    "        continue\n",
    "    ids.append(p_id)\n",
    "    playlists.append(playlist)\n",
    "\n",
    "with ProcessPoolExecutor() as executor:\n",
    "    results = list( tqdm( executor.map( parallel_fuc, ids, playlists ), total = len(ids) ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5c2ff8eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(176212, {'coherence': 0.1212876820832488, 'pl_var': 0.34021938, 'sq_var': 0.29895496})\n",
      "27\n"
     ]
    }
   ],
   "source": [
    "print(list(var_data.items())[102123-1])\n",
    "print(len(playlist_list[176212]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1594d8f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78575"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ac7ae62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./rearranged.tsv',mode = 'w') as f:\n",
    "    for p_id, playlist in results:\n",
    "\n",
    "        f.write(str(p_id))\n",
    "\n",
    "        for t_id in playlist:\n",
    "            f.write('\\t'+str(t_id))\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "208fbb54",
   "metadata": {},
   "source": [
    "# srec用に変形"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bcde9b4",
   "metadata": {},
   "source": [
    "## settint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "369e36a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8466b1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "durations = []\n",
    "\n",
    "with open( '/home/tamak/master_exp/ThirtyMusic/relations/sessions.idomaar', mode = 'r' ) as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "    for line in lines:\n",
    "        event_type, session_id, timestamp, info, data = line.split()\n",
    "\n",
    "        data = json.loads(data)\n",
    "        obs = data['objects']\n",
    "\n",
    "        for ob in obs:\n",
    "            durations.append(ob['playtime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "09ec6477",
   "metadata": {},
   "outputs": [],
   "source": [
    "durations = [ duration for duration in durations if duration > 0 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "01a31512",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #nowplaying : 2011/7/11~\n",
    "min_time = 1310256000\t\n",
    "max_time = 1399766400"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a203fec0",
   "metadata": {},
   "source": [
    "## 整形"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cb7137cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "from random import choice\n",
    "import random\n",
    "\n",
    "mdfy_list = []\n",
    "random.seed(2025)\n",
    "session_id = -1\n",
    "\n",
    "with open('./rearranged.tsv', mode = 'r') as f:\n",
    "\n",
    "    for line in f.readlines():\n",
    "        time = randint(min_time,max_time)\n",
    "        data = line.split('\\t')\n",
    "        p_id = data[0]\n",
    "        session_id += 1\n",
    "        session = data[2:]\n",
    "\n",
    "        tmp = []\n",
    "        if len(session) == 1:\n",
    "            continue\n",
    "        for i, track_id in enumerate(session):\n",
    "            tmp.append( [ str(session_id), str(time), str(track_id.replace('\\t','')) ] )\n",
    "\n",
    "            deltatime = choice(durations)\n",
    "            time += deltatime\n",
    "\n",
    "        if time > max_time:\n",
    "            diff = time-max_time\n",
    "            for d in tmp:\n",
    "                d[1] = str(int(d[1]) - diff)\n",
    "\n",
    "        mdfy_list += tmp\n",
    "\n",
    "\n",
    "with open('./experiment_train_full.txt', mode = 'w') as f:\n",
    "\n",
    "    f.write('SessionId\\tItemId\\tTime\\n')\n",
    "\n",
    "    for data in mdfy_list:\n",
    "        session_id, timestamp, track_id = data\n",
    "        f.write(session_id.rstrip('\\t')+'\\t'+track_id.rstrip('\\n')+'\\t'+str(timestamp)+'\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "coherence",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
