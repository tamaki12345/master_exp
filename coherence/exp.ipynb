{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa00787f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting anyio==4.4.0 (from -r ../coh_analysis/requirements.txt (line 1))\n",
      "  Using cached anyio-4.4.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting argon2-cffi==23.1.0 (from -r ../coh_analysis/requirements.txt (line 2))\n",
      "  Using cached argon2_cffi-23.1.0-py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting argon2-cffi-bindings==21.2.0 (from -r ../coh_analysis/requirements.txt (line 3))\n",
      "  Using cached argon2_cffi_bindings-21.2.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting arrow==1.3.0 (from -r ../coh_analysis/requirements.txt (line 4))\n",
      "  Using cached arrow-1.3.0-py3-none-any.whl.metadata (7.5 kB)\n",
      "Collecting asttokens==2.4.1 (from -r ../coh_analysis/requirements.txt (line 5))\n",
      "  Using cached asttokens-2.4.1-py2.py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting async-lru==2.0.4 (from -r ../coh_analysis/requirements.txt (line 6))\n",
      "  Using cached async_lru-2.0.4-py3-none-any.whl.metadata (4.5 kB)\n",
      "Collecting attrs==24.2.0 (from -r ../coh_analysis/requirements.txt (line 7))\n",
      "  Downloading attrs-24.2.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting babel==2.16.0 (from -r ../coh_analysis/requirements.txt (line 8))\n",
      "  Downloading babel-2.16.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting beautifulsoup4==4.12.3 (from -r ../coh_analysis/requirements.txt (line 9))\n",
      "  Using cached beautifulsoup4-4.12.3-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting bidict==0.23.1 (from -r ../coh_analysis/requirements.txt (line 10))\n",
      "  Downloading bidict-0.23.1-py3-none-any.whl.metadata (8.7 kB)\n",
      "Collecting bleach==6.1.0 (from -r ../coh_analysis/requirements.txt (line 11))\n",
      "  Using cached bleach-6.1.0-py3-none-any.whl.metadata (30 kB)\n",
      "Collecting CausalInference==0.1.3 (from -r ../coh_analysis/requirements.txt (line 12))\n",
      "  Downloading CausalInference-0.1.3-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting certifi==2024.8.30 (from -r ../coh_analysis/requirements.txt (line 13))\n",
      "  Downloading certifi-2024.8.30-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting cffi==1.17.1 (from -r ../coh_analysis/requirements.txt (line 14))\n",
      "  Downloading cffi-1.17.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting charset-normalizer==3.3.2 (from -r ../coh_analysis/requirements.txt (line 15))\n",
      "  Downloading charset_normalizer-3.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (33 kB)\n",
      "Requirement already satisfied: comm==0.2.2 in /home/tamak/.local/lib/python3.11/site-packages (from -r ../coh_analysis/requirements.txt (line 16)) (0.2.2)\n",
      "Collecting contourpy==1.3.0 (from -r ../coh_analysis/requirements.txt (line 17))\n",
      "  Downloading contourpy-1.3.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.4 kB)\n",
      "Collecting cycler==0.12.1 (from -r ../coh_analysis/requirements.txt (line 18))\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting debugpy==1.8.5 (from -r ../coh_analysis/requirements.txt (line 19))\n",
      "  Downloading debugpy-1.8.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.1 kB)\n",
      "Collecting decorator==5.1.1 (from -r ../coh_analysis/requirements.txt (line 20))\n",
      "  Using cached decorator-5.1.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting defusedxml==0.7.1 (from -r ../coh_analysis/requirements.txt (line 21))\n",
      "  Using cached defusedxml-0.7.1-py2.py3-none-any.whl.metadata (32 kB)\n",
      "Collecting executing==2.1.0 (from -r ../coh_analysis/requirements.txt (line 22))\n",
      "  Downloading executing-2.1.0-py2.py3-none-any.whl.metadata (8.9 kB)\n",
      "Collecting fastjsonschema==2.20.0 (from -r ../coh_analysis/requirements.txt (line 23))\n",
      "  Downloading fastjsonschema-2.20.0-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting fonttools==4.53.1 (from -r ../coh_analysis/requirements.txt (line 24))\n",
      "  Downloading fonttools-4.53.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (162 kB)\n",
      "Collecting fqdn==1.5.1 (from -r ../coh_analysis/requirements.txt (line 25))\n",
      "  Using cached fqdn-1.5.1-py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting h11==0.14.0 (from -r ../coh_analysis/requirements.txt (line 26))\n",
      "  Using cached h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Collecting httpcore==1.0.5 (from -r ../coh_analysis/requirements.txt (line 27))\n",
      "  Using cached httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting httpx==0.27.2 (from -r ../coh_analysis/requirements.txt (line 28))\n",
      "  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting idna==3.8 (from -r ../coh_analysis/requirements.txt (line 29))\n",
      "  Downloading idna-3.8-py3-none-any.whl.metadata (9.9 kB)\n",
      "Requirement already satisfied: ipykernel==6.29.5 in /home/tamak/.local/lib/python3.11/site-packages (from -r ../coh_analysis/requirements.txt (line 30)) (6.29.5)\n",
      "Collecting ipython==8.27.0 (from -r ../coh_analysis/requirements.txt (line 31))\n",
      "  Downloading ipython-8.27.0-py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting isoduration==20.11.0 (from -r ../coh_analysis/requirements.txt (line 32))\n",
      "  Using cached isoduration-20.11.0-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting jedi==0.19.1 (from -r ../coh_analysis/requirements.txt (line 33))\n",
      "  Using cached jedi-0.19.1-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting Jinja2==3.1.4 (from -r ../coh_analysis/requirements.txt (line 34))\n",
      "  Using cached jinja2-3.1.4-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting joblib==1.4.2 (from -r ../coh_analysis/requirements.txt (line 35))\n",
      "  Using cached joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting json5==0.9.25 (from -r ../coh_analysis/requirements.txt (line 36))\n",
      "  Using cached json5-0.9.25-py3-none-any.whl.metadata (30 kB)\n",
      "Collecting jsonpointer==3.0.0 (from -r ../coh_analysis/requirements.txt (line 37))\n",
      "  Downloading jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting jsonschema==4.23.0 (from -r ../coh_analysis/requirements.txt (line 38))\n",
      "  Downloading jsonschema-4.23.0-py3-none-any.whl.metadata (7.9 kB)\n",
      "Collecting jsonschema-specifications==2023.12.1 (from -r ../coh_analysis/requirements.txt (line 39))\n",
      "  Using cached jsonschema_specifications-2023.12.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting jupyter-events==0.10.0 (from -r ../coh_analysis/requirements.txt (line 40))\n",
      "  Using cached jupyter_events-0.10.0-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting jupyter-lsp==2.2.5 (from -r ../coh_analysis/requirements.txt (line 41))\n",
      "  Using cached jupyter_lsp-2.2.5-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting jupyter_client==8.6.2 (from -r ../coh_analysis/requirements.txt (line 42))\n",
      "  Using cached jupyter_client-8.6.2-py3-none-any.whl.metadata (8.3 kB)\n",
      "Requirement already satisfied: jupyter_core==5.7.2 in /home/tamak/.local/lib/python3.11/site-packages (from -r ../coh_analysis/requirements.txt (line 43)) (5.7.2)\n",
      "Collecting jupyter_server==2.14.2 (from -r ../coh_analysis/requirements.txt (line 44))\n",
      "  Downloading jupyter_server-2.14.2-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting jupyter_server_terminals==0.5.3 (from -r ../coh_analysis/requirements.txt (line 45))\n",
      "  Using cached jupyter_server_terminals-0.5.3-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting jupyterlab==4.2.5 (from -r ../coh_analysis/requirements.txt (line 46))\n",
      "  Downloading jupyterlab-4.2.5-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting jupyterlab_pygments==0.3.0 (from -r ../coh_analysis/requirements.txt (line 47))\n",
      "  Using cached jupyterlab_pygments-0.3.0-py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting jupyterlab_server==2.27.3 (from -r ../coh_analysis/requirements.txt (line 48))\n",
      "  Downloading jupyterlab_server-2.27.3-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting kiwisolver==1.4.7 (from -r ../coh_analysis/requirements.txt (line 49))\n",
      "  Downloading kiwisolver-1.4.7-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.3 kB)\n",
      "Collecting MarkupSafe==2.1.5 (from -r ../coh_analysis/requirements.txt (line 50))\n",
      "  Downloading MarkupSafe-2.1.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
      "Collecting matplotlib==3.9.2 (from -r ../coh_analysis/requirements.txt (line 51))\n",
      "  Downloading matplotlib-3.9.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: matplotlib-inline==0.1.7 in /home/tamak/.local/lib/python3.11/site-packages (from -r ../coh_analysis/requirements.txt (line 52)) (0.1.7)\n",
      "Collecting mistune==3.0.2 (from -r ../coh_analysis/requirements.txt (line 53))\n",
      "  Using cached mistune-3.0.2-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting more-itertools==10.5.0 (from -r ../coh_analysis/requirements.txt (line 54))\n",
      "  Downloading more_itertools-10.5.0-py3-none-any.whl.metadata (36 kB)\n",
      "Collecting nbclient==0.10.0 (from -r ../coh_analysis/requirements.txt (line 55))\n",
      "  Using cached nbclient-0.10.0-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting nbconvert==7.16.4 (from -r ../coh_analysis/requirements.txt (line 56))\n",
      "  Using cached nbconvert-7.16.4-py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting nbformat==5.10.4 (from -r ../coh_analysis/requirements.txt (line 57))\n",
      "  Using cached nbformat-5.10.4-py3-none-any.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: nest-asyncio==1.6.0 in /home/tamak/.local/lib/python3.11/site-packages (from -r ../coh_analysis/requirements.txt (line 58)) (1.6.0)\n",
      "Collecting notebook==7.2.2 (from -r ../coh_analysis/requirements.txt (line 59))\n",
      "  Downloading notebook-7.2.2-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting notebook_shim==0.2.4 (from -r ../coh_analysis/requirements.txt (line 60))\n",
      "  Using cached notebook_shim-0.2.4-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting numpy==2.1.1 (from -r ../coh_analysis/requirements.txt (line 61))\n",
      "  Downloading numpy-2.1.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
      "Collecting overrides==7.7.0 (from -r ../coh_analysis/requirements.txt (line 62))\n",
      "  Using cached overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting packaging==24.1 (from -r ../coh_analysis/requirements.txt (line 63))\n",
      "  Downloading packaging-24.1-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting pandas==2.2.2 (from -r ../coh_analysis/requirements.txt (line 64))\n",
      "  Downloading pandas-2.2.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (19 kB)\n",
      "Collecting pandocfilters==1.5.1 (from -r ../coh_analysis/requirements.txt (line 65))\n",
      "  Using cached pandocfilters-1.5.1-py2.py3-none-any.whl.metadata (9.0 kB)\n",
      "Requirement already satisfied: parso==0.8.4 in /home/tamak/.local/lib/python3.11/site-packages (from -r ../coh_analysis/requirements.txt (line 66)) (0.8.4)\n",
      "Collecting patsy==0.5.6 (from -r ../coh_analysis/requirements.txt (line 67))\n",
      "  Downloading patsy-0.5.6-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: pexpect==4.9.0 in /home/tamak/.local/lib/python3.11/site-packages (from -r ../coh_analysis/requirements.txt (line 68)) (4.9.0)\n",
      "Collecting pickleshare==0.7.5 (from -r ../coh_analysis/requirements.txt (line 69))\n",
      "  Downloading pickleshare-0.7.5-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting pillow==10.4.0 (from -r ../coh_analysis/requirements.txt (line 70))\n",
      "  Downloading pillow-10.4.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (9.2 kB)\n",
      "Collecting platformdirs==4.3.2 (from -r ../coh_analysis/requirements.txt (line 71))\n",
      "  Downloading platformdirs-4.3.2-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting prometheus_client==0.20.0 (from -r ../coh_analysis/requirements.txt (line 72))\n",
      "  Using cached prometheus_client-0.20.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting prompt_toolkit==3.0.47 (from -r ../coh_analysis/requirements.txt (line 73))\n",
      "  Downloading prompt_toolkit-3.0.47-py3-none-any.whl.metadata (6.4 kB)\n",
      "Collecting psutil==6.0.0 (from -r ../coh_analysis/requirements.txt (line 74))\n",
      "  Downloading psutil-6.0.0-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (21 kB)\n",
      "Requirement already satisfied: ptyprocess==0.7.0 in /home/tamak/.local/lib/python3.11/site-packages (from -r ../coh_analysis/requirements.txt (line 75)) (0.7.0)\n",
      "Requirement already satisfied: pure_eval==0.2.3 in /home/tamak/.local/lib/python3.11/site-packages (from -r ../coh_analysis/requirements.txt (line 76)) (0.2.3)\n",
      "Collecting pycparser==2.22 (from -r ../coh_analysis/requirements.txt (line 77))\n",
      "  Using cached pycparser-2.22-py3-none-any.whl.metadata (943 bytes)\n",
      "Collecting Pygments==2.18.0 (from -r ../coh_analysis/requirements.txt (line 78))\n",
      "  Using cached pygments-2.18.0-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting pyparsing==3.1.4 (from -r ../coh_analysis/requirements.txt (line 79))\n",
      "  Downloading pyparsing-3.1.4-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: python-dateutil==2.9.0.post0 in /home/tamak/.local/lib/python3.11/site-packages (from -r ../coh_analysis/requirements.txt (line 80)) (2.9.0.post0)\n",
      "Collecting python-json-logger==2.0.7 (from -r ../coh_analysis/requirements.txt (line 81))\n",
      "  Using cached python_json_logger-2.0.7-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting pytz==2024.1 (from -r ../coh_analysis/requirements.txt (line 82))\n",
      "  Downloading pytz-2024.1-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting PyYAML==6.0.2 (from -r ../coh_analysis/requirements.txt (line 83))\n",
      "  Downloading PyYAML-6.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\n",
      "Collecting pyzmq==26.2.0 (from -r ../coh_analysis/requirements.txt (line 84))\n",
      "  Downloading pyzmq-26.2.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (6.2 kB)\n",
      "Collecting referencing==0.35.1 (from -r ../coh_analysis/requirements.txt (line 85))\n",
      "  Using cached referencing-0.35.1-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting requests==2.32.3 (from -r ../coh_analysis/requirements.txt (line 86))\n",
      "  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting rfc3339-validator==0.1.4 (from -r ../coh_analysis/requirements.txt (line 87))\n",
      "  Using cached rfc3339_validator-0.1.4-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting rfc3986-validator==0.1.1 (from -r ../coh_analysis/requirements.txt (line 88))\n",
      "  Using cached rfc3986_validator-0.1.1-py2.py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting rpds-py==0.20.0 (from -r ../coh_analysis/requirements.txt (line 89))\n",
      "  Downloading rpds_py-0.20.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
      "Collecting scikit-learn==1.5.2 (from -r ../coh_analysis/requirements.txt (line 90))\n",
      "  Downloading scikit_learn-1.5.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
      "Collecting scipy==1.14.1 (from -r ../coh_analysis/requirements.txt (line 91))\n",
      "  Downloading scipy-1.14.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
      "Collecting seaborn==0.13.2 (from -r ../coh_analysis/requirements.txt (line 92))\n",
      "  Downloading seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting Send2Trash==1.8.3 (from -r ../coh_analysis/requirements.txt (line 93))\n",
      "  Using cached Send2Trash-1.8.3-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting six==1.16.0 (from -r ../coh_analysis/requirements.txt (line 94))\n",
      "  Downloading six-1.16.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting sniffio==1.3.1 (from -r ../coh_analysis/requirements.txt (line 95))\n",
      "  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting soupsieve==2.6 (from -r ../coh_analysis/requirements.txt (line 96))\n",
      "  Downloading soupsieve-2.6-py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: stack-data==0.6.3 in /home/tamak/.local/lib/python3.11/site-packages (from -r ../coh_analysis/requirements.txt (line 97)) (0.6.3)\n",
      "Collecting statsmodels==0.14.2 (from -r ../coh_analysis/requirements.txt (line 98))\n",
      "  Downloading statsmodels-0.14.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.2 kB)\n",
      "Collecting terminado==0.18.1 (from -r ../coh_analysis/requirements.txt (line 99))\n",
      "  Using cached terminado-0.18.1-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting threadpoolctl==3.5.0 (from -r ../coh_analysis/requirements.txt (line 100))\n",
      "  Using cached threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting tinycss2==1.3.0 (from -r ../coh_analysis/requirements.txt (line 101))\n",
      "  Using cached tinycss2-1.3.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting tornado==6.4.1 (from -r ../coh_analysis/requirements.txt (line 102))\n",
      "  Using cached tornado-6.4.1-cp38-abi3-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: traitlets==5.14.3 in /home/tamak/.local/lib/python3.11/site-packages (from -r ../coh_analysis/requirements.txt (line 103)) (5.14.3)\n",
      "Collecting typeguard==4.3.0 (from -r ../coh_analysis/requirements.txt (line 104))\n",
      "  Downloading typeguard-4.3.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting types-python-dateutil==2.9.0.20240906 (from -r ../coh_analysis/requirements.txt (line 105))\n",
      "  Downloading types_python_dateutil-2.9.0.20240906-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting typing_extensions==4.12.2 (from -r ../coh_analysis/requirements.txt (line 106))\n",
      "  Using cached typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting tzdata==2024.1 (from -r ../coh_analysis/requirements.txt (line 107))\n",
      "  Downloading tzdata-2024.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting uri-template==1.3.0 (from -r ../coh_analysis/requirements.txt (line 108))\n",
      "  Using cached uri_template-1.3.0-py3-none-any.whl.metadata (8.8 kB)\n",
      "Collecting urllib3==2.2.2 (from -r ../coh_analysis/requirements.txt (line 109))\n",
      "  Downloading urllib3-2.2.2-py3-none-any.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: wcwidth==0.2.13 in /home/tamak/.local/lib/python3.11/site-packages (from -r ../coh_analysis/requirements.txt (line 110)) (0.2.13)\n",
      "Collecting webcolors==24.8.0 (from -r ../coh_analysis/requirements.txt (line 111))\n",
      "  Downloading webcolors-24.8.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting webencodings==0.5.1 (from -r ../coh_analysis/requirements.txt (line 112))\n",
      "  Using cached webencodings-0.5.1-py2.py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting websocket-client==1.8.0 (from -r ../coh_analysis/requirements.txt (line 113))\n",
      "  Using cached websocket_client-1.8.0-py3-none-any.whl.metadata (8.0 kB)\n",
      "Requirement already satisfied: setuptools>=40.1.0 in /home/tamak/anaconda3/envs/coherence/lib/python3.11/site-packages (from jupyterlab==4.2.5->-r ../coh_analysis/requirements.txt (line 46)) (80.9.0)\n",
      "Using cached anyio-4.4.0-py3-none-any.whl (86 kB)\n",
      "Using cached argon2_cffi-23.1.0-py3-none-any.whl (15 kB)\n",
      "Using cached argon2_cffi_bindings-21.2.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (86 kB)\n",
      "Using cached arrow-1.3.0-py3-none-any.whl (66 kB)\n",
      "Using cached asttokens-2.4.1-py2.py3-none-any.whl (27 kB)\n",
      "Using cached async_lru-2.0.4-py3-none-any.whl (6.1 kB)\n",
      "Downloading attrs-24.2.0-py3-none-any.whl (63 kB)\n",
      "Downloading babel-2.16.0-py3-none-any.whl (9.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.6/9.6 MB\u001b[0m \u001b[31m79.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached beautifulsoup4-4.12.3-py3-none-any.whl (147 kB)\n",
      "Downloading bidict-0.23.1-py3-none-any.whl (32 kB)\n",
      "Using cached bleach-6.1.0-py3-none-any.whl (162 kB)\n",
      "Downloading CausalInference-0.1.3-py3-none-any.whl (51 kB)\n",
      "Downloading certifi-2024.8.30-py3-none-any.whl (167 kB)\n",
      "Downloading cffi-1.17.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (467 kB)\n",
      "Downloading charset_normalizer-3.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (140 kB)\n",
      "Downloading contourpy-1.3.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (323 kB)\n",
      "Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading debugpy-1.8.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached decorator-5.1.1-py3-none-any.whl (9.1 kB)\n",
      "Using cached defusedxml-0.7.1-py2.py3-none-any.whl (25 kB)\n",
      "Downloading executing-2.1.0-py2.py3-none-any.whl (25 kB)\n",
      "Downloading fastjsonschema-2.20.0-py3-none-any.whl (23 kB)\n",
      "Downloading fonttools-4.53.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m78.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached fqdn-1.5.1-py3-none-any.whl (9.1 kB)\n",
      "Using cached h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Using cached httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
      "Downloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
      "Downloading idna-3.8-py3-none-any.whl (66 kB)\n",
      "Downloading ipython-8.27.0-py3-none-any.whl (818 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m819.0/819.0 kB\u001b[0m \u001b[31m40.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading prompt_toolkit-3.0.47-py3-none-any.whl (386 kB)\n",
      "Using cached isoduration-20.11.0-py3-none-any.whl (11 kB)\n",
      "Using cached jedi-0.19.1-py2.py3-none-any.whl (1.6 MB)\n",
      "Using cached jinja2-3.1.4-py3-none-any.whl (133 kB)\n",
      "Using cached joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Using cached json5-0.9.25-py3-none-any.whl (30 kB)\n",
      "Downloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
      "Downloading jsonschema-4.23.0-py3-none-any.whl (88 kB)\n",
      "Using cached jsonschema_specifications-2023.12.1-py3-none-any.whl (18 kB)\n",
      "Using cached jupyter_events-0.10.0-py3-none-any.whl (18 kB)\n",
      "Using cached jupyter_lsp-2.2.5-py3-none-any.whl (69 kB)\n",
      "Using cached jupyter_client-8.6.2-py3-none-any.whl (105 kB)\n",
      "Downloading jupyter_server-2.14.2-py3-none-any.whl (383 kB)\n",
      "Using cached jupyter_server_terminals-0.5.3-py3-none-any.whl (13 kB)\n",
      "Downloading jupyterlab-4.2.5-py3-none-any.whl (11.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m82.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading jupyterlab_server-2.27.3-py3-none-any.whl (59 kB)\n",
      "Using cached jupyterlab_pygments-0.3.0-py3-none-any.whl (15 kB)\n",
      "Downloading kiwisolver-1.4.7-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m64.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading MarkupSafe-2.1.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (28 kB)\n",
      "Downloading matplotlib-3.9.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.3/8.3 MB\u001b[0m \u001b[31m79.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached mistune-3.0.2-py3-none-any.whl (47 kB)\n",
      "Downloading more_itertools-10.5.0-py3-none-any.whl (60 kB)\n",
      "Using cached nbclient-0.10.0-py3-none-any.whl (25 kB)\n",
      "Using cached nbconvert-7.16.4-py3-none-any.whl (257 kB)\n",
      "Using cached nbformat-5.10.4-py3-none-any.whl (78 kB)\n",
      "Downloading notebook-7.2.2-py3-none-any.whl (5.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m75.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached notebook_shim-0.2.4-py3-none-any.whl (13 kB)\n",
      "Downloading numpy-2.1.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.3/16.3 MB\u001b[0m \u001b[31m82.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached overrides-7.7.0-py3-none-any.whl (17 kB)\n",
      "Downloading packaging-24.1-py3-none-any.whl (53 kB)\n",
      "Downloading pandas-2.2.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.0/13.0 MB\u001b[0m \u001b[31m81.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached pandocfilters-1.5.1-py2.py3-none-any.whl (8.7 kB)\n",
      "Downloading patsy-0.5.6-py2.py3-none-any.whl (233 kB)\n",
      "Downloading pickleshare-0.7.5-py2.py3-none-any.whl (6.9 kB)\n",
      "Downloading pillow-10.4.0-cp311-cp311-manylinux_2_28_x86_64.whl (4.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m68.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading platformdirs-4.3.2-py3-none-any.whl (18 kB)\n",
      "Using cached prometheus_client-0.20.0-py3-none-any.whl (54 kB)\n",
      "Downloading psutil-6.0.0-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (290 kB)\n",
      "Using cached pycparser-2.22-py3-none-any.whl (117 kB)\n",
      "Using cached pygments-2.18.0-py3-none-any.whl (1.2 MB)\n",
      "Downloading pyparsing-3.1.4-py3-none-any.whl (104 kB)\n",
      "Using cached python_json_logger-2.0.7-py3-none-any.whl (8.1 kB)\n",
      "Downloading pytz-2024.1-py2.py3-none-any.whl (505 kB)\n",
      "Downloading PyYAML-6.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (762 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m763.0/763.0 kB\u001b[0m \u001b[31m46.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyzmq-26.2.0-cp311-cp311-manylinux_2_28_x86_64.whl (869 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m869.2/869.2 kB\u001b[0m \u001b[31m54.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached referencing-0.35.1-py3-none-any.whl (26 kB)\n",
      "Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Downloading urllib3-2.2.2-py3-none-any.whl (121 kB)\n",
      "Using cached rfc3339_validator-0.1.4-py2.py3-none-any.whl (3.5 kB)\n",
      "Using cached rfc3986_validator-0.1.1-py2.py3-none-any.whl (4.2 kB)\n",
      "Downloading rpds_py-0.20.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (354 kB)\n",
      "Downloading scikit_learn-1.5.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m42.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading scipy-1.14.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (41.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.2/41.2 MB\u001b[0m \u001b[31m83.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
      "Using cached Send2Trash-1.8.3-py3-none-any.whl (18 kB)\n",
      "Downloading six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
      "Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Downloading soupsieve-2.6-py3-none-any.whl (36 kB)\n",
      "Downloading statsmodels-0.14.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.7/10.7 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0mm\n",
      "\u001b[?25hUsing cached terminado-0.18.1-py3-none-any.whl (14 kB)\n",
      "Using cached threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Using cached tinycss2-1.3.0-py3-none-any.whl (22 kB)\n",
      "Using cached tornado-6.4.1-cp38-abi3-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (436 kB)\n",
      "Downloading typeguard-4.3.0-py3-none-any.whl (35 kB)\n",
      "Downloading types_python_dateutil-2.9.0.20240906-py3-none-any.whl (9.7 kB)\n",
      "Using cached typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "Downloading tzdata-2024.1-py2.py3-none-any.whl (345 kB)\n",
      "Using cached uri_template-1.3.0-py3-none-any.whl (11 kB)\n",
      "Downloading webcolors-24.8.0-py3-none-any.whl (15 kB)\n",
      "Using cached webencodings-0.5.1-py2.py3-none-any.whl (11 kB)\n",
      "Using cached websocket_client-1.8.0-py3-none-any.whl (58 kB)\n",
      "Installing collected packages: webencodings, pytz, pickleshare, fastjsonschema, CausalInference, websocket-client, webcolors, urllib3, uri-template, tzdata, typing_extensions, types-python-dateutil, tornado, tinycss2, threadpoolctl, soupsieve, sniffio, six, Send2Trash, rpds-py, rfc3986-validator, pyzmq, PyYAML, python-json-logger, pyparsing, Pygments, pycparser, psutil, prompt_toolkit, prometheus_client, platformdirs, pillow, pandocfilters, packaging, overrides, numpy, more-itertools, mistune, MarkupSafe, kiwisolver, jupyterlab_pygments, jsonpointer, json5, joblib, jedi, idna, h11, fqdn, fonttools, executing, defusedxml, decorator, debugpy, cycler, charset-normalizer, certifi, bidict, babel, attrs, async-lru, typeguard, terminado, scipy, rfc3339-validator, requests, referencing, patsy, Jinja2, httpcore, contourpy, cffi, bleach, beautifulsoup4, asttokens, anyio, scikit-learn, pandas, matplotlib, jupyter_server_terminals, jupyter_client, jsonschema-specifications, httpx, arrow, argon2-cffi-bindings, statsmodels, seaborn, jsonschema, isoduration, ipython, argon2-cffi, nbformat, nbclient, jupyter-events, nbconvert, jupyter_server, notebook_shim, jupyterlab_server, jupyter-lsp, jupyterlab, notebook\n",
      "\u001b[2K  Attempting uninstall: typing_extensions━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m  7/100\u001b[0m [urllib3]\n",
      "\u001b[2K    Found existing installation: typing_extensions 4.13.2━━━━━\u001b[0m \u001b[32m  7/100\u001b[0m [urllib3]\n",
      "\u001b[2K    Uninstalling typing_extensions-4.13.2:━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m  7/100\u001b[0m [urllib3]\n",
      "\u001b[2K      Successfully uninstalled typing_extensions-4.13.2━━━━━━━━━━━\u001b[0m \u001b[32m 10/100\u001b[0m [typing_extensions]\n",
      "\u001b[2K  Attempting uninstall: tornado━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 10/100\u001b[0m [typing_extensions]\n",
      "\u001b[2K    Found existing installation: tornado 6.5━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 10/100\u001b[0m [typing_extensions]\n",
      "\u001b[2K    Uninstalling tornado-6.5:━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 10/100\u001b[0m [typing_extensions]\n",
      "\u001b[2K      Successfully uninstalled tornado-6.5━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 10/100\u001b[0m [typing_extensions]\n",
      "\u001b[2K  Attempting uninstall: six[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 12/100\u001b[0m [tornado]sions]\n",
      "\u001b[2K    Found existing installation: six 1.17.0━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 12/100\u001b[0m [tornado]\n",
      "\u001b[2K    Uninstalling six-1.17.0:━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 12/100\u001b[0m [tornado]\n",
      "\u001b[2K      Successfully uninstalled six-1.17.0━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 12/100\u001b[0m [tornado]\n",
      "\u001b[2K  Attempting uninstall: pyzmq\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 18/100\u001b[0m [Send2Trash]\n",
      "\u001b[2K    Found existing installation: pyzmq 26.4.0━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 18/100\u001b[0m [Send2Trash]\n",
      "\u001b[2K    Uninstalling pyzmq-26.4.0:━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 18/100\u001b[0m [Send2Trash]\n",
      "\u001b[2K      Successfully uninstalled pyzmq-26.4.0━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 18/100\u001b[0m [Send2Trash]\n",
      "\u001b[2K  Attempting uninstall: Pygments[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 24/100\u001b[0m [pyparsing]\n",
      "\u001b[2K    Found existing installation: Pygments 2.19.1━━━━━━━━━━━━━━\u001b[0m \u001b[32m 24/100\u001b[0m [pyparsing]\n",
      "\u001b[2K    Uninstalling Pygments-2.19.1:━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 24/100\u001b[0m [pyparsing]\n",
      "\u001b[2K      Successfully uninstalled Pygments-2.19.1━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 24/100\u001b[0m [pyparsing]\n",
      "\u001b[2K  Attempting uninstall: psutil0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 26/100\u001b[0m [pycparser]\n",
      "\u001b[2K    Found existing installation: psutil 7.0.0━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 26/100\u001b[0m [pycparser]\n",
      "\u001b[2K    Uninstalling psutil-7.0.0:90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 26/100\u001b[0m [pycparser]\n",
      "\u001b[2K      Successfully uninstalled psutil-7.0.0━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 26/100\u001b[0m [pycparser]\n",
      "\u001b[2K  Attempting uninstall: prompt_toolkit━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 27/100\u001b[0m [psutil]\n",
      "\u001b[2K    Found existing installation: prompt_toolkit 3.0.51━━━━━━━━\u001b[0m \u001b[32m 27/100\u001b[0m [psutil]\n",
      "\u001b[2K    Uninstalling prompt_toolkit-3.0.51:━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 27/100\u001b[0m [psutil]\n",
      "\u001b[2K      Successfully uninstalled prompt_toolkit-3.0.51━━━━━━━━━━\u001b[0m \u001b[32m 27/100\u001b[0m [psutil]\n",
      "\u001b[2K  Attempting uninstall: platformdirs0m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 28/100\u001b[0m [prompt_toolkit]\n",
      "\u001b[2K    Found existing installation: platformdirs 4.3.8━━━━━━━━━━━\u001b[0m \u001b[32m 28/100\u001b[0m [prompt_toolkit]\n",
      "\u001b[2K    Uninstalling platformdirs-4.3.8:━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 28/100\u001b[0m [prompt_toolkit]\n",
      "\u001b[2K      Successfully uninstalled platformdirs-4.3.8━━━━━━━━━━━━━\u001b[0m \u001b[32m 28/100\u001b[0m [prompt_toolkit]\n",
      "\u001b[2K  Attempting uninstall: packagingm\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 31/100\u001b[0m [pillow]kit]\n",
      "\u001b[2K    Found existing installation: packaging 25.0━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 31/100\u001b[0m [pillow]\n",
      "\u001b[2K    Uninstalling packaging-25.0:90m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 31/100\u001b[0m [pillow]\n",
      "\u001b[2K      Successfully uninstalled packaging-25.0━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 31/100\u001b[0m [pillow]\n",
      "\u001b[2K  Attempting uninstall: jedim\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 43/100\u001b[0m [joblib]\n",
      "\u001b[2K    Found existing installation: jedi 0.19.2━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 43/100\u001b[0m [joblib]\n",
      "\u001b[2K    Uninstalling jedi-0.19.2:m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 43/100\u001b[0m [joblib]\n",
      "\u001b[2K      Successfully uninstalled jedi-0.19.2━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 43/100\u001b[0m [joblib]\n",
      "\u001b[2K  Attempting uninstall: executing90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 48/100\u001b[0m [fonttools]\n",
      "\u001b[2K    Found existing installation: executing 2.2.0━━━━━━━━━━━━━━\u001b[0m \u001b[32m 48/100\u001b[0m [fonttools]\n",
      "\u001b[2K    Uninstalling executing-2.2.0:\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 48/100\u001b[0m [fonttools]\n",
      "\u001b[2K      Successfully uninstalled executing-2.2.0━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 48/100\u001b[0m [fonttools]\n",
      "\u001b[2K  Attempting uninstall: decorator91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 49/100\u001b[0m [executing]\n",
      "\u001b[2K    Found existing installation: decorator 5.2.1━━━━━━━━━━━━━━\u001b[0m \u001b[32m 49/100\u001b[0m [executing]\n",
      "\u001b[2K    Uninstalling decorator-5.2.1:\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 49/100\u001b[0m [executing]\n",
      "\u001b[2K      Successfully uninstalled decorator-5.2.1━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 49/100\u001b[0m [executing]\n",
      "\u001b[2K  Attempting uninstall: debugpym╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 49/100\u001b[0m [executing]\n",
      "\u001b[2K    Found existing installation: debugpy 1.8.14━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 49/100\u001b[0m [executing]\n",
      "\u001b[2K    Uninstalling debugpy-1.8.14:╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 49/100\u001b[0m [executing]\n",
      "\u001b[2K      Successfully uninstalled debugpy-1.8.14━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 49/100\u001b[0m [executing]\n",
      "\u001b[2K  Attempting uninstall: asttokens━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m 70/100\u001b[0m [cffi]]]]\n",
      "\u001b[2K    Found existing installation: asttokens 3.0.090m━━━━━━━━━━━\u001b[0m \u001b[32m 70/100\u001b[0m [cffi]\n",
      "\u001b[2K    Uninstalling asttokens-3.0.0:[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m 70/100\u001b[0m [cffi]\n",
      "\u001b[2K      Successfully uninstalled asttokens-3.0.0\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m 70/100\u001b[0m [cffi]\n",
      "\u001b[2K  Attempting uninstall: jupyter_client\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m \u001b[32m 77/100\u001b[0m [matplotlib]n]\n",
      "\u001b[2K    Found existing installation: jupyter_client 8.6.3━━━━━━━━━\u001b[0m \u001b[32m 77/100\u001b[0m [matplotlib]\n",
      "\u001b[2K    Uninstalling jupyter_client-8.6.3:\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m \u001b[32m 77/100\u001b[0m [matplotlib]\n",
      "\u001b[2K      Successfully uninstalled jupyter_client-8.6.30m━━━━━━━━━\u001b[0m \u001b[32m 77/100\u001b[0m [matplotlib]\n",
      "\u001b[2K  Attempting uninstall: ipython━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━\u001b[0m \u001b[32m 85/100\u001b[0m [seaborn]els]\n",
      "\u001b[2K    Found existing installation: ipython 9.2.0m╺\u001b[0m\u001b[90m━━━━━\u001b[0m \u001b[32m 85/100\u001b[0m [seaborn]\n",
      "\u001b[2K    Uninstalling ipython-9.2.0:━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━\u001b[0m \u001b[32m 85/100\u001b[0m [seaborn]\n",
      "\u001b[2K      Successfully uninstalled ipython-9.2.090m╺\u001b[0m\u001b[90m━━━━━\u001b[0m \u001b[32m 85/100\u001b[0m [seaborn]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m100/100\u001b[0m [notebook]notebook]b]convert]\n",
      "\u001b[1A\u001b[2KSuccessfully installed CausalInference-0.1.3 Jinja2-3.1.4 MarkupSafe-2.1.5 PyYAML-6.0.2 Pygments-2.18.0 Send2Trash-1.8.3 anyio-4.4.0 argon2-cffi-23.1.0 argon2-cffi-bindings-21.2.0 arrow-1.3.0 asttokens-2.4.1 async-lru-2.0.4 attrs-24.2.0 babel-2.16.0 beautifulsoup4-4.12.3 bidict-0.23.1 bleach-6.1.0 certifi-2024.8.30 cffi-1.17.1 charset-normalizer-3.3.2 contourpy-1.3.0 cycler-0.12.1 debugpy-1.8.5 decorator-5.1.1 defusedxml-0.7.1 executing-2.1.0 fastjsonschema-2.20.0 fonttools-4.53.1 fqdn-1.5.1 h11-0.14.0 httpcore-1.0.5 httpx-0.27.2 idna-3.8 ipython-8.27.0 isoduration-20.11.0 jedi-0.19.1 joblib-1.4.2 json5-0.9.25 jsonpointer-3.0.0 jsonschema-4.23.0 jsonschema-specifications-2023.12.1 jupyter-events-0.10.0 jupyter-lsp-2.2.5 jupyter_client-8.6.2 jupyter_server-2.14.2 jupyter_server_terminals-0.5.3 jupyterlab-4.2.5 jupyterlab_pygments-0.3.0 jupyterlab_server-2.27.3 kiwisolver-1.4.7 matplotlib-3.9.2 mistune-3.0.2 more-itertools-10.5.0 nbclient-0.10.0 nbconvert-7.16.4 nbformat-5.10.4 notebook-7.2.2 notebook_shim-0.2.4 numpy-2.1.1 overrides-7.7.0 packaging-24.1 pandas-2.2.2 pandocfilters-1.5.1 patsy-0.5.6 pickleshare-0.7.5 pillow-10.4.0 platformdirs-4.3.2 prometheus_client-0.20.0 prompt_toolkit-3.0.47 psutil-6.0.0 pycparser-2.22 pyparsing-3.1.4 python-json-logger-2.0.7 pytz-2024.1 pyzmq-26.2.0 referencing-0.35.1 requests-2.32.3 rfc3339-validator-0.1.4 rfc3986-validator-0.1.1 rpds-py-0.20.0 scikit-learn-1.5.2 scipy-1.14.1 seaborn-0.13.2 six-1.16.0 sniffio-1.3.1 soupsieve-2.6 statsmodels-0.14.2 terminado-0.18.1 threadpoolctl-3.5.0 tinycss2-1.3.0 tornado-6.4.1 typeguard-4.3.0 types-python-dateutil-2.9.0.20240906 typing_extensions-4.12.2 tzdata-2024.1 uri-template-1.3.0 urllib3-2.2.2 webcolors-24.8.0 webencodings-0.5.1 websocket-client-1.8.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -r ../coh_analysis/requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a4d4368",
   "metadata": {},
   "source": [
    "SPD->id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f86235f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['9cc0cfd4d7d7885102480dd99e7a90d6', 'Elvis Costello', '(The Angels Wanna Wear My) Red Shoes', 'HARD ROCK 2010\\n']\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "track_dict = defaultdict()\n",
    "artist_dict = defaultdict()\n",
    "\n",
    "with open('../modify_dataset/spotify_playlists_dataset/SPD_modified.tsv', mode = 'r') as f:\n",
    "    lines = f.readlines()[1:]\n",
    "\n",
    "print(lines[0].split('\\t,\\t'))\n",
    "for line in lines:\n",
    "\n",
    "    user_id, artistname, trackname, playlistname = line.split('\\t,\\t')\n",
    "\n",
    "    if not track_dict.get( (artistname, trackname) ):\n",
    "        track_dict[ (artistname, trackname) ] = len(track_dict)\n",
    "\n",
    "    if not artist_dict.get( artistname ):\n",
    "        artist_dict[artistname] =  len(artist_dict)\n",
    "        \n",
    "with open('../modify_dataset/spotify_playlists_dataset/track_id.tsv', mode = 'w') as f:\n",
    "    \n",
    "    for (artistname, trackname), id in track_dict.items():\n",
    "        f.write(artistname+'\\t'+trackname+'\\t'+str(id)+'\\n')\n",
    "\n",
    "\n",
    "with open('../modify_dataset/spotify_playlists_dataset/artist_id.tsv', mode = 'w') as f:\n",
    "    \n",
    "    for artistname, id in artist_dict.items():\n",
    "        f.write(artistname+'\\t'+str(id)+'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14222adf",
   "metadata": {},
   "source": [
    "プレイリストid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406db915",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "playlist_set = set()\n",
    "playlist_id = defaultdict()\n",
    "user_playlist_pairs = defaultdict(list)\n",
    "\n",
    "with open('../modify_dataset/spotify_playlists_dataset/user_playlist_pairs.tsv', mode = 'r') as f:\n",
    "    \n",
    "    for line in f.readlines():\n",
    "        data = line.split('\\t,\\t')\n",
    "        \n",
    "        user = data[0]\n",
    "        title = data[1]\n",
    "        playlist = data[2:]\n",
    "        playlist = tuple(np.array(playlist, dtype = int))\n",
    "        \n",
    "        if playlist in playlist_set:\n",
    "            user_playlist_pairs[user].append( (title, playlist_id[playlist]) )\n",
    "            \n",
    "        else:\n",
    "            playlist_set.add(playlist)\n",
    "            playlist_id[playlist] = len(playlist_id)\n",
    "            \n",
    "with open('../modify_dataset/spotify_playlists_dataset/user_playlist_id.tsv', mode = 'w') as f:\n",
    "    for user, ids in user_playlist_pairs.items():\n",
    "        f.write(user)\n",
    "        \n",
    "        for id in ids:\n",
    "            f.write('\\t'+str(id))\n",
    "        \n",
    "        f.write('\\n')\n",
    "        \n",
    "with open('../modify_dataset/spotify_playlists_dataset/playlist_id.tsv', mode = 'w') as f:\n",
    "    for playlist, id in sorted(playlist_id.items(), key = lambda:x int(x[1])):\n",
    "        f.write(id)\n",
    "        \n",
    "        for track in playlist:\n",
    "            f.write('\\t'+str(track))\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68dd4a33",
   "metadata": {},
   "source": [
    "## id読み取り"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaeff897",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "track_dict = defaultdict()\n",
    "\n",
    "with open('../modify_dataset/spotify_playlists_dataset/artist_id.tsv', mode = 'r') as f:\n",
    "    \n",
    "    for line in f.readlines():\n",
    "        artistname, id = line.split('\\t')\n",
    "        artist_dict[artistname] = int(id)\n",
    "        \n",
    "artist_dict = defaultdict()\n",
    "track_artist_id = defaultdict()\n",
    "\n",
    "with open('../modify_dataset/spotify_playlists_dataset/track_id.tsv', mode = 'r') as f:\n",
    "    \n",
    "    for line in f.readlines():\n",
    "        artistname, trackname, id = line.split('\\t')\n",
    "        artist_dict[ (artistname, trackname) ] = int(id)\n",
    "        track_artist_id[ int(id) ] = artist_dict[artistname]\n",
    "        \n",
    "playlist_list = []\n",
    "with open('../modify_dataset/spotify_playlists_dataset/playlist_id.tsv', mode = 'r') as f:\n",
    "    \n",
    "    for line in f.readlines():\n",
    "        data = line.split('\\t')\n",
    "        playlist = tuple(data[1:])\n",
    "        playlist_list.append(playlist)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d7dc98",
   "metadata": {},
   "source": [
    "## プレイリスト-アーティスト行列"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b69a997e",
   "metadata": {},
   "source": [
    "プレイリストごとアーティストカウント"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00af6c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "playlist_artist_counts = {}\n",
    "artist_in_playlist_count = defaultdict(int)\n",
    "\n",
    "for p_id, playlist in tqdm( enumerate(playlist_list), total = len(playlist_list) ):\n",
    "\n",
    "    artist_count = defaultdict(int)\n",
    "    \n",
    "    for track in playlist:\n",
    "        artist = track_artist_id[track]\n",
    "        artist_count[ artist ] += 1\n",
    "        artist_in_playlist_count[ artist ] += 1\n",
    "        \n",
    "    playlist_artist_counts[p_id] = artist_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a39d2c3",
   "metadata": {},
   "source": [
    "GitHubから関数拝借"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28356e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import lil_matrix, coo_matrix\n",
    "\n",
    "def normalize_data(data):\n",
    "    \n",
    "    # 各プレイリストのアーティスト回数について\n",
    "    for pid, playlist_artist_ids in data.items():\n",
    "        max_term = max(playlist_artist_ids.values())\n",
    "        \n",
    "        # プレイリストの各アーティストについて\n",
    "        for artist_id, count in playlist_artist_ids.items():\n",
    "            \n",
    "            # tf-idf計算\n",
    "            tf = count / max_term\n",
    "            idf = np.log(len(data) / artist_in_playlist_count[artist_id])\n",
    "            \n",
    "            # 受け取ったプレイリスト-アーティスト回数をtf-idfに\n",
    "            playlist_artist_ids[artist_id] = tf * idf\n",
    "            \n",
    "    return data\n",
    "\n",
    "def init_matrix(data):\n",
    "    n = len(artist_dict)\n",
    "    m = len(data)\n",
    "    matrix = lil_matrix((m, n), dtype=np.float32)\n",
    "    for i, playlist_artist_ids in enumerate(data.values()):\n",
    "        for artist_id, count in playlist_artist_ids.items():\n",
    "            matrix[i, artist_id] = count\n",
    "    return coo_matrix(matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9292218",
   "metadata": {},
   "source": [
    "プレイリスト-アーティストtf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd1876c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = normalize_data(playlist_artist_counts)\n",
    "playlist_artist_matrix = init_matrix(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff17509",
   "metadata": {},
   "source": [
    "## プレイリストのcoherence計算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b474b71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# tf-idf類似度\n",
    "def embedding_similarity(a_embeddings, b_embeddings):\n",
    "    return np.mean(cosine_distances(a_embeddings.T, b_embeddings.T))\n",
    "\n",
    "# プレイリスト内分散\n",
    "def playlist_variance(embeddings):\n",
    "    sum_ = 0\n",
    "    n = len(embeddings)\n",
    "    for i, a_track in enumerate(embeddings[:-1]):\n",
    "        for j, b_track in enumerate(embeddings[i + 1:]):\n",
    "            sum_ += embedding_similarity(a_track, b_track) ** 2\n",
    "    div = n * (n - 1)\n",
    "    \n",
    "    # 分散と組み合わせ数を返す\n",
    "    return sum_ / div, div // 2\n",
    "\n",
    "# プレイリスト内連続分散\n",
    "def sequential_variance(embeddings):\n",
    "    sum_ = 0\n",
    "    n = len(embeddings)\n",
    "    for i, a_artists in enumerate(embeddings[:-1]):\n",
    "        b_artists = embeddings[i + 1]\n",
    "        sum_ += embedding_similarity(a_artists, b_artists) ** 2\n",
    "\n",
    "    # 分散と組み合わせ数を返す\n",
    "    return sum_ / (n - 1) / 2, n - 1\n",
    "\n",
    "def embedding_to_variance(pid, embeddings):\n",
    "    pl_var, p_c = playlist_variance(embeddings)\n",
    "    sq_var, s_c = sequential_variance(embeddings)\n",
    "    return pid, sq_var, pl_var, s_c, p_c, len(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8af127",
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.features\n",
    "import time\n",
    "from more_itertools import batched\n",
    "\n",
    "start_time = time.time()\n",
    "variances = {}\n",
    "\n",
    "for i, batch in enumerate(batched(playlists, 2350)):\n",
    "    \n",
    "    print(f\"--- {(time.time() - start_time)} seconds for {i} ---\")\n",
    "    start_time = time.time()\n",
    "    current_size = len(variances)\n",
    "\n",
    "    futures = []\n",
    "    with concurrent.futures.ProcessPoolExecutor(max_workers=47) as executor:\n",
    "        print(f\"Starting {i}\")\n",
    "        for p_id, playlist in enumerate(batch):\n",
    "            if p_id in variances:\n",
    "                continue\n",
    "            embeddings = [matrix[:, track_to_ids[tid]] for tid in playlist]\n",
    "\n",
    "            future = executor.submit(embedding_to_variance, pid=p_id, embeddings=embeddings)\n",
    "            futures.append(future)\n",
    "        print(f\"Waiting {i}\")\n",
    "        for f in futures:\n",
    "            pid, sq_var, pl_var, s_c, p_c, track_len = f.result()\n",
    "            variances[pid] = sq_var, pl_var, s_c, p_c, track_len\n",
    "    \n",
    "with open('./SPD_variances.tsv', mode = 'w') as f:\n",
    "    for pid, (sq_var, pl_var, s_c, p_c, len_embeddings) in variances.items():\n",
    "        f.write(f'{pid}\\t{sq_var}\\t{pl_var}\\t{s_c}\\t{p_c}\\t{len_embeddings}\\t{1-sq_var/pl_var}')        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "coherence",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
